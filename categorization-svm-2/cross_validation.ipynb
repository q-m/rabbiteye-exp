{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementation on new data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import sys\n",
    "import csv\n",
    "import time\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from featurize import tokenize_dict\n",
    "from tqdm import tqdm_notebook\n",
    "from unidecode import unidecode\n",
    "\n",
    "from collections import defaultdict\n",
    "from collections import Counter\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.cross_validation import cross_val_predict\n",
    "from sklearn.cross_validation import LeaveOneLabelOut\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "source = 'data/product_nuts_with_product_info.jsonl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data_pn_usage = []\n",
    "\n",
    "with open(source) as f:\n",
    "    for line in tqdm_notebook(f):\n",
    "        data_pn_usage.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "id_tokens = [tokenize_dict(d) for d in data_pn_usage]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What needs to be done\n",
    "\n",
    "- remove doubles from nuts products\n",
    "- check that we only include nuts product with wich the usage is linked to at least three products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# removes doubles\n",
    "known = set()\n",
    "no_doubles = []\n",
    "\n",
    "for d in tqdm_notebook(id_tokens):\n",
    "    tok = ' '.join(d['tokens'])\n",
    "    if tok in known: \n",
    "        continue\n",
    "    no_doubles.append(d)\n",
    "    known.add(tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# makes a dict where each tuple has one usage and all the product_ids linked to it\n",
    "k = [{x['usage']: x['product_id']} for x in no_doubles]\n",
    "dd = defaultdict(list)\n",
    "\n",
    "for d in tqdm_notebook(k): \n",
    "    for key, value in d.iteritems():\n",
    "        dd[key].append(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# checks if a usage is linked to at least 3 products\n",
    "allowed_usage = []\n",
    "for x in tqdm_notebook(dd.items()):\n",
    "    if len(set(x[1])) > 2:\n",
    "        allowed_usage.append(x[0])\n",
    "        \n",
    "set_allowed_usage = set(allowed_usage)\n",
    "\n",
    "complete = []\n",
    "for x in tqdm_notebook(no_doubles):\n",
    "    if x['usage'] in set_allowed_usage:\n",
    "        complete.append(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "text_per_item_pn = [' '.join(tokens['tokens']) for tokens in complete]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(min_df=1, binary=True)\n",
    "X = vectorizer.fit_transform(text_per_item_pn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Y = [x['usage'] for x in complete]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_validation, Y_train, Y_validation = train_test_split(X, Y, test_size=0.2, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X:  (140071, 29395) Y:  140071\n",
      "X:  (112056, 29395) Y:  112056\n",
      "X:  (28015, 29395)  Y:  28015\n"
     ]
    }
   ],
   "source": [
    "print 'X: ', X.shape, 'Y: ', len(Y)\n",
    "print 'X: ', X_train.shape, 'Y: ', len(Y_train)\n",
    "print 'X: ', X_validation.shape, ' Y: ', len(Y_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python2.7/dist-packages/sklearn/cross_validation.py:532: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of labels for any class cannot be less than n_folds=5.\n",
      "  % (min_labels, self.n_folds)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear][LibLinear][LibLinear]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python2.7/dist-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear][LibLinear]"
     ]
    }
   ],
   "source": [
    "clf = LinearSVC(random_state = 2, verbose = 1)\n",
    "scores = cross_val_score(clf, X_train, Y_train, cv=5, scoring='recall_macro') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall macro: 0.77 (+/- 0.02)\n"
     ]
    }
   ],
   "source": [
    "print \"recall macro: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]"
     ]
    }
   ],
   "source": [
    "clf.fit(X_train, Y_train)\n",
    "predictions = clf.predict(X_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python2.7/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/lib/python2.7/dist-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "def classifaction_report_csv(report):\n",
    "    report_data = []\n",
    "    lines = report.encode('ascii', 'ignore').split('\\n')\n",
    "    #for line in (lines[2:-3] + [lines[-2]]):\n",
    "    for line in (lines[2:-3] + [lines[-2]]):\n",
    "        row = {}\n",
    "        row_data = line.strip().split('  ')\n",
    "        row_data = [x for x in row_data if x != '']\n",
    "        row['class'] = row_data[0]\n",
    "        row['precision'] = row_data[1]\n",
    "        row['recall'] = row_data[2]\n",
    "        row['f1_score'] = row_data[3]\n",
    "        row['support'] = row_data[4]\n",
    "        report_data.append(row)\n",
    "    dataframe = pd.DataFrame.from_dict(report_data)\n",
    "    #dataframe.to_csv('classification_report.csv', index = False)\n",
    "    return dataframe\n",
    "\n",
    "report = classification_report(Y_validation, predictions)\n",
    "df = classifaction_report_csv(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "macro recall score:  0.77511104049\n",
      "micro recall score:  0.859539532393\n"
     ]
    }
   ],
   "source": [
    "print 'macro recall score: ', recall_score(Y_validation, predictions, average = 'macro')\n",
    "print 'micro recall score: ', recall_score(Y_validation, predictions, average = 'micro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Reliable Recall Macro Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "macro recall score:  0.788133086876\n"
     ]
    }
   ],
   "source": [
    "report_data = []\n",
    "lines = report.encode('ascii', 'ignore').split('\\n')\n",
    "for line in (lines[2:-3] + [lines[-2]]):\n",
    "    row = {}\n",
    "    row_data = line.strip().split('  ')\n",
    "    row_data = [x for x in row_data if x != '']\n",
    "    row['class'] = row_data[0]\n",
    "    row['precision'] = row_data[1]\n",
    "    row['recall'] = row_data[2]\n",
    "    row['f1_score'] = row_data[3]\n",
    "    row['support'] = row_data[4]\n",
    "    report_data.append(row)\n",
    "    \n",
    "    \n",
    "recall = []\n",
    "for d in report_data:\n",
    "    if d['support'].strip() != '0':\n",
    "        recall.append(d['recall'])\n",
    "        \n",
    "n_recall = [float(x) for x in recall]\n",
    "print 'macro recall score: ', sum(n_recall) / len(recall)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "widgets": {
   "state": {
    "05a8816e02e94a0fae63035fad5ca410": {
     "views": [
      {
       "cell_index": 8
      }
     ]
    },
    "23441d202d1c4d638ea64cf6e19e7e3e": {
     "views": [
      {
       "cell_index": 3
      }
     ]
    },
    "5569f31991604f489137a256f30636fc": {
     "views": [
      {
       "cell_index": 6
      }
     ]
    },
    "a831e0a841b8473c9015e1ca0cb21ac4": {
     "views": [
      {
       "cell_index": 8
      }
     ]
    },
    "e2ed0687784d409a8696872092ef5688": {
     "views": [
      {
       "cell_index": 7
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
